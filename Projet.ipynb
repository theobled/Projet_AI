{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 0.9396\n",
      "Baseline training time (s): 2.067254066467285\n",
      "Baseline total params: 235146\n",
      "Baseline non-zero params: 235146\n",
      "Baseline size (MB): 0.8970108032226562\n",
      "Generation 1/15 | Best fitness: 0.8501\n",
      "Generation 2/15 | Best fitness: 0.8524\n",
      "Generation 3/15 | Best fitness: 0.8524\n",
      "Generation 4/15 | Best fitness: 0.8791\n",
      "Generation 5/15 | Best fitness: 0.8791\n",
      "Generation 6/15 | Best fitness: 0.8791\n",
      "Generation 7/15 | Best fitness: 0.8856\n",
      "Generation 8/15 | Best fitness: 0.8856\n",
      "Generation 9/15 | Best fitness: 0.8880\n",
      "Generation 10/15 | Best fitness: 0.8897\n",
      "Generation 11/15 | Best fitness: 0.8920\n",
      "Generation 12/15 | Best fitness: 0.8976\n",
      "Generation 13/15 | Best fitness: 0.8995\n",
      "Generation 14/15 | Best fitness: 0.8995\n",
      "Generation 15/15 | Best fitness: 0.8995\n",
      "Best pruned accuracy: 0.9011\n",
      "Pruned fine-tuning time (s): 2.0492663383483887\n",
      "Pruned total params: 235146\n",
      "Pruned non-zero params: 220248\n",
      "Pruned size (MB): 0.8970108032226562\n",
      "Final sparsity: 0.06335638284299971\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Total Params</th>\n",
       "      <th>Non-zero Params</th>\n",
       "      <th>Size (MB)</th>\n",
       "      <th>Train Time (s)</th>\n",
       "      <th>Sparsity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.9396</td>\n",
       "      <td>235146</td>\n",
       "      <td>235146</td>\n",
       "      <td>0.897011</td>\n",
       "      <td>2.067254</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GA Pruned</td>\n",
       "      <td>0.9011</td>\n",
       "      <td>235146</td>\n",
       "      <td>220248</td>\n",
       "      <td>0.897011</td>\n",
       "      <td>2.049266</td>\n",
       "      <td>0.063356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model  Accuracy  Total Params  Non-zero Params  Size (MB)  \\\n",
       "0   Baseline    0.9396        235146           235146   0.897011   \n",
       "1  GA Pruned    0.9011        235146           220248   0.897011   \n",
       "\n",
       "   Train Time (s)  Sparsity  \n",
       "0        2.067254  0.000000  \n",
       "1        2.049266  0.063356  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===============================================================\n",
    "#              OPTION A - GENETIC PRUNING NOTEBOOK\n",
    "#        Inspired by Reinikainen (2024) - Transformer Pruning\n",
    "# ===============================================================\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import random, copy, pandas as pd\n",
    "\n",
    "# ===============================================================\n",
    "# 1. DATA LOADING (MNIST)\n",
    "# ===============================================================\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_data = datasets.MNIST(\"./data\", train=True, download=True, transform=transform)\n",
    "test_data  = datasets.MNIST(\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=256, shuffle=True)\n",
    "test_loader  = DataLoader(test_data, batch_size=256, shuffle=False)\n",
    "\n",
    "# ===============================================================\n",
    "# 2. MODEL DEFINITION\n",
    "# Small MLP used as a proxy to reproduce LLM pruning behaviour\n",
    "# ===============================================================\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "model = MLP()\n",
    "\n",
    "# ===============================================================\n",
    "# 3. TRAINING FUNCTION (returns training time)\n",
    "# ===============================================================\n",
    "\n",
    "def train_model(m, epochs=1):\n",
    "    m.train()\n",
    "    opt = optim.Adam(m.parameters(), lr=1e-3)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    for _ in range(epochs):\n",
    "        for X, y in train_loader:\n",
    "            opt.zero_grad()\n",
    "            loss = loss_fn(m(X), y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "    end = time.time()\n",
    "    return end - start\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Train baseline model\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "baseline_train_time = train_model(model, 1)\n",
    "\n",
    "# ===============================================================\n",
    "# 4. BASELINE EVALUATION\n",
    "# ===============================================================\n",
    "\n",
    "def evaluate(mdl):\n",
    "    mdl.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            correct += (mdl(X).argmax(1) == y).sum().item()\n",
    "    return correct / len(test_data)\n",
    "\n",
    "baseline_acc = evaluate(model)\n",
    "print(\"Baseline accuracy:\", baseline_acc)\n",
    "print(\"Baseline training time (s):\", baseline_train_time)\n",
    "\n",
    "# ===============================================================\n",
    "# 5. MODEL SIZE FUNCTIONS\n",
    "# ===============================================================\n",
    "\n",
    "def count_parameters(model):\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    nonzero = sum((p != 0).sum().item() for p in model.parameters())\n",
    "    return total, nonzero\n",
    "\n",
    "def model_size_mb(model):\n",
    "    total_bytes = 0\n",
    "    for p in model.parameters():\n",
    "        total_bytes += p.nelement() * p.element_size()\n",
    "    return total_bytes / (1024*1024)\n",
    "\n",
    "# Baseline model size\n",
    "baseline_total, baseline_nonzero = count_parameters(model)\n",
    "baseline_size_mb = model_size_mb(model)\n",
    "\n",
    "print(\"Baseline total params:\", baseline_total)\n",
    "print(\"Baseline non-zero params:\", baseline_nonzero)\n",
    "print(\"Baseline size (MB):\", baseline_size_mb)\n",
    "\n",
    "# ===============================================================\n",
    "# 6. MASK ENCODING FOR PRUNING (Binary masks)\n",
    "# ===============================================================\n",
    "\n",
    "def apply_mask(mdl, mask):\n",
    "    pruned = copy.deepcopy(mdl)\n",
    "    idx = 0\n",
    "    for p in pruned.parameters():\n",
    "        num = p.numel()\n",
    "        flat = p.data.view(-1).cpu().numpy()\n",
    "        mask_slice = mask[idx:idx+num]\n",
    "        flat[mask_slice == 0] = 0\n",
    "        p.data = torch.from_numpy(flat.reshape(p.shape)).float()\n",
    "        idx += num\n",
    "    return pruned\n",
    "\n",
    "def random_mask(model, sparsity):\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    keep = int(total * (1 - sparsity))\n",
    "    bits = np.zeros(total, dtype=int)\n",
    "    bits[:keep] = 1\n",
    "    np.random.shuffle(bits)\n",
    "    return bits\n",
    "\n",
    "# ===============================================================\n",
    "# 7. FITNESS FUNCTION (Accuracy - Sparsity Penalty)\n",
    "# ===============================================================\n",
    "\n",
    "def fitness(mask):\n",
    "    pruned = apply_mask(model, mask)\n",
    "    acc = evaluate(pruned)\n",
    "    sparsity = 1 - np.mean(mask)\n",
    "    return acc - 2.0 * abs(sparsity - SPARSITY_TARGET)   # weighted combination (Reinikainen-inspired)\n",
    "\n",
    "# ===============================================================\n",
    "# 8. GENETIC ALGORITHM\n",
    "# ===============================================================\n",
    "\n",
    "POP = 40  \n",
    "GEN = 15\n",
    "SPARSITY_TARGET = 0.60  # 60% pruning\n",
    "\n",
    "# Initial population\n",
    "population = [random_mask(model, SPARSITY_TARGET) for _ in range(POP)]\n",
    "\n",
    "for gen in range(GEN):\n",
    "    scores = [fitness(ind) for ind in population]\n",
    "    best_idx = int(np.argmax(scores))\n",
    "    print(f\"Generation {gen+1}/{GEN} | Best fitness: {max(scores):.4f}\")\n",
    "\n",
    "    # Select top half\n",
    "    top_half = [population[i] for i in np.argsort(scores)[-POP//2:]]\n",
    "\n",
    "    # Generate offspring\n",
    "    new_population = top_half.copy()\n",
    "\n",
    "    while len(new_population) < POP:\n",
    "        p1, p2 = random.sample(top_half, 2)\n",
    "        point = random.randint(0, len(p1)-1)\n",
    "        child = np.concatenate([p1[:point], p2[point:]])\n",
    "\n",
    "        # Mutation\n",
    "        if random.random() < 0.1:\n",
    "            r = random.randint(0, len(child)-1)\n",
    "            child[r] = 1 - child[r]\n",
    "\n",
    "        new_population.append(child)\n",
    "\n",
    "    population = new_population\n",
    "\n",
    "# ===============================================================\n",
    "# 9. BEST PRUNED MODEL EVALUATION\n",
    "# ===============================================================\n",
    "\n",
    "best_mask = population[np.argmax([fitness(ind) for ind in population])]\n",
    "best_pruned_model = apply_mask(model, best_mask)\n",
    "best_acc = evaluate(best_pruned_model)\n",
    "\n",
    "print(\"Best pruned accuracy:\", best_acc)\n",
    "\n",
    "# ---- Fine-tuning pruned model ----\n",
    "pruned_train_time = train_model(best_pruned_model, 1)\n",
    "\n",
    "print(\"Pruned fine-tuning time (s):\", pruned_train_time)\n",
    "\n",
    "# ===============================================================\n",
    "# 10. PRUNED MODEL SIZE\n",
    "# ===============================================================\n",
    "\n",
    "pruned_total, pruned_nonzero = count_parameters(best_pruned_model)\n",
    "pruned_size_mb = model_size_mb(best_pruned_model)\n",
    "sparsity_final = 1 - (pruned_nonzero / pruned_total)\n",
    "\n",
    "print(\"Pruned total params:\", pruned_total)\n",
    "print(\"Pruned non-zero params:\", pruned_nonzero)\n",
    "print(\"Pruned size (MB):\", pruned_size_mb)\n",
    "print(\"Final sparsity:\", sparsity_final)\n",
    "\n",
    "# ===============================================================\n",
    "# 11. SUMMARY TABLE\n",
    "# ===============================================================\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    \"Model\": [\"Baseline\", \"GA Pruned\"],\n",
    "    \"Accuracy\": [baseline_acc, best_acc],\n",
    "    \"Total Params\": [baseline_total, pruned_total],\n",
    "    \"Non-zero Params\": [baseline_nonzero, pruned_nonzero],\n",
    "    \"Size (MB)\": [baseline_size_mb, pruned_size_mb],\n",
    "    \"Train Time (s)\": [baseline_train_time, pruned_train_time],\n",
    "    \"Sparsity\": [0.0, sparsity_final]\n",
    "})\n",
    "\n",
    "summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
